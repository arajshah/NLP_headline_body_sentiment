{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: tqdm in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U torch transformers tqdm sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1299, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "df = pd.read_csv(\"../data/clean_gvfc_sentiment_v2.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "/Users/araj/Documents/Code/Python Files/NLP Projects/NLP_headline_body_sentiment/venv/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "device      = 0 if torch.cuda.is_available() else -1          # -1 → CPU\n",
    "sent_pipe   = pipeline(\"sentiment-analysis\",\n",
    "                       model=model,\n",
    "                       tokenizer=tokenizer,\n",
    "                       device=device,\n",
    "                       return_all_scores=True,\n",
    "                       truncation=True,\n",
    "                       max_length=512,\n",
    "                       batch_size=32)                         # tune for RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL2SCORE = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "\n",
    "def weighted_score(result):\n",
    "    \"\"\"Turn list of {'label','score'} dicts into a single number.\"\"\"\n",
    "    return sum(d[\"score\"] * LABEL2SCORE[d[\"label\"].lower()] for d in result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_tokens(text, tokenizer, tokens_per_chunk=450):\n",
    "    \"\"\"\n",
    "    Split a long string into pieces, each ≤ tokens_per_chunk,\n",
    "    **without** needing sentence tokenisation.\n",
    "    \"\"\"\n",
    "    # Encode once to avoid repeated tokenisation\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    for i in range(0, len(tokens), tokens_per_chunk):\n",
    "        chunk_ids = tokens[i : i + tokens_per_chunk]\n",
    "        yield tokenizer.decode(chunk_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test headline: cremated remains of las vegas mass shooter to be kept in safe deposit box, brother says\n",
      "Type of result: <class 'list'>\n",
      "Result structure: [[{'label': 'negative', 'score': 0.1584518402814865}, {'label': 'neutral', 'score': 0.8270642161369324}, {'label': 'positive', 'score': 0.014483900740742683}]]\n"
     ]
    }
   ],
   "source": [
    "# Add this cell to debug the output structure\n",
    "test_headline = df[\"headline_clean\"].iloc[0]\n",
    "result = sent_pipe(test_headline)\n",
    "print(f\"Test headline: {test_headline}\")\n",
    "print(f\"Type of result: {type(result)}\")\n",
    "print(f\"Result structure: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1299/1299 [01:06<00:00, 19.58it/s]\n",
      "100%|██████████| 1299/1299 [01:22<00:00, 15.68it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# 1️⃣  Headlines – text is short, single pass\n",
    "df[\"sent_head\"] = df[\"headline_clean\"].progress_apply(\n",
    "    lambda x: weighted_score(sent_pipe(x)[0])\n",
    ")\n",
    "\n",
    "# 2️⃣  Bodies – may be long, so chunk then average\n",
    "def body_sentiment(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return None\n",
    "    chunks  = list(chunk_by_tokens(text, tokenizer))\n",
    "    results = sent_pipe(chunks)               # returns list of lists\n",
    "    scores  = [weighted_score(r) for r in results]\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "df[\"sent_body\"] = df[\"body_clean\"].progress_apply(body_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sent_head    sent_body\n",
      "count  1299.000000  1299.000000\n",
      "mean     -0.402119    -0.258562\n",
      "std       0.340166     0.410197\n",
      "min      -0.928732    -0.932480\n",
      "25%      -0.689916    -0.616164\n",
      "50%      -0.450826    -0.259065\n",
      "75%      -0.131545     0.024327\n",
      "max       0.829489     0.967569\n",
      "                                       headline_text  sent_head  sent_body\n",
      "0  Cremated remains of Las Vegas mass shooter to ...  -0.143968  -0.324479\n",
      "1  Florida shooter a troubled loner with white su...  -0.777282  -0.812513\n",
      "2  Vernon Hills teen accused of wearing white sup...  -0.472589  -0.116213\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"sent_head\", \"sent_body\"]].describe())\n",
    "print(df.head(3)[[\"headline_text\", \"sent_head\", \"sent_body\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/gvfc_with_sentiment.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
